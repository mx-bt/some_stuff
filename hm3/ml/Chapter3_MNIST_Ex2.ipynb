{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "\n",
    "mnist_dwnld = fetch_openml(\"mnist_784\",version=1)\n",
    "print(mnist_dwnld.keys())\n",
    "print(type(mnist_dwnld))\n",
    "\n",
    "mnist_dwnload = fetch_openml(\"mnist_784\", version=1)\n",
    "\n",
    "# Save the Bunch object\n",
    "dump(mnist_dwnload, \"mnist_dataset_784_v1.joblib\")\n",
    "\n",
    "#30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "\n",
    "mnist_loaded = load(\"C:/Users/MaxB2/Documents/Machine_Is_Learning/mnist_dataset_784_v1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  <class 'numpy.uint8'>\n",
      "After:  <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Value type tranformation and train-test split\"\"\"\n",
    "X,y = mnist_loaded[\"data\"],mnist_loaded[\"target\"]\n",
    "y = y.astype(np.uint8)\n",
    "print(\"Before: \",type(y[rd.randint(0,X.shape[0]-1)]))\n",
    "y = y.astype(np.uint8)\n",
    "print(\"After: \",type(y[rd.randint(0,X.shape[0]-1)]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000],X[60000:],y[:60000],y[60000:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred1 = knn.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_knn_1 = accuracy_score(y_test, y_pred1)\n",
    "print(acc_knn_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  1472   Label:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAC1UlEQVR4nO3dUW7aQBRA0bjqvoCVYVYGrMxdQGyVIRR8q3M+EUks5epJMx7DtCzL8gUxvz59AfAM4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIlSbgkCZck4ZIkXJKES5JwSRIuScIl6fenL2APbrfbt9dOp9PDP3+9XldfPx6PT14Rf2PikiRckoRLknBJsjj7Wl+cjbhcLg+/14LtNUxckoRLknBJEi5JwiXJrsLX+kp/a6fgfD4//N7D4fDQ32KciUuScEkSLknCJWlalmX59EXs0TRNP/4dawuxrbO7jDFxSRIuScIlSbgkCZckuwob5nlefX3k0PgaTwS/holLknBJEi5JwiXJedw323qi2OJsjIlLknBJEi5JwiVJuCTZVXizrVvGW7eYWWfikiRckoRLknBJch530Cue/l3j3zDGxCVJuCQJlyThkiRcktzyHbR24PunXzfFOBOXJOGSJFyShEuSW76D3PLdBxOXJOGSJFyShEuScElyy3fQyHf58u+YuCQJlyThkiRckizOdmLtTK8Pe95m4pIkXJKES5JwSRIuSXYVdsKuwhgTlyThkiRckoRLksXZTtzv909fQoqJS5JwSRIuScIlSbgk2VXYCR8OPcbEJUm4JAmXJOGSZHG2Y1sLNud0TVyihEuScEkSLknCJcmuwo7ZPdhm4pIkXJKES5JwSbI4G+Rp3H0wcUkSLknCJUm4JAmXJLsKgw6Hw7fXPKH7fiYuScIlSbgkCZekaVmW5dMXUTdN08Pv3Tpju7bom+f5ySv6/5m4JAmXJOGSJFyShEuSW74vYGPm/UxckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJlyThkiRckoRLknBJEi5JwiVJuCQJl6Q/bvBfJa2mL1AAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Number Demonstration\"\"\"\n",
    "index = rd.randint(0,X.shape[0]-1)\n",
    "image_array = np.array(X.iloc[index])\n",
    "\n",
    "def plot_digit(Data):\n",
    "    digit_array = Data.reshape(28,28)\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(digit_array,cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "    #plt.show()\n",
    "print(\"Index: \", index,\"  Label: \",y[index])\n",
    "plot_digit(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaxB2\\AppData\\Local\\Temp\\ipykernel_8884\\1257280377.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train_augmented_output = input_data_list.append(pd.DataFrame(shifted_pics_data, columns=input_data_list.columns), ignore_index=True)\n",
      "C:\\Users\\MaxB2\\AppData\\Local\\Temp\\ipykernel_8884\\1257280377.py:28: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_train_augmented_output = input_label_list.append(pd.Series(shifted_pics_labels), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Classifier and CV Accuracy Calculation\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.model_selection import cross_val_score\\nbest_estimator = KNeighborsClassifier(n_neighbors=4, weights=\\'distance\\')\\naccuracy_scores = cross_val_score(best_estimator,X_train_augmented,y_train_augmented,cv=3, scoring=\"accuracy\")\\nprint(\"Mean Accuracy: \",round(np.mean(accuracy_scores),2))'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Data Augmentation XXXXYYYYZZZZ\n",
    "X_train_base = X_train.copy()\n",
    "y_train_base = y_train.copy()\n",
    "\n",
    "from scipy.ndimage import shift\n",
    "import pandas as pd\n",
    "\n",
    "sa = 1\n",
    "desired_shifts = np.array([[0,sa],[0,-sa],[sa,0],[-sa,0]])\n",
    "\n",
    "def augment_data(input_data_list,input_label_list,shift_list):\n",
    "    shifted_pics_data = []\n",
    "    shifted_pics_labels = []\n",
    "    for i in range(len(input_data_list)): # input_list to be augmented\n",
    "        for s in range(len(shift_list)): # shift_list with [v,h] vectors to be applied\n",
    "            single_image_data = np.array(input_data_list.iloc[i]) \n",
    "\n",
    "            digit_image = np.array(single_image_data.reshape(28,28))\n",
    "            #int(np.sqrt(single_image_data[:1].shape[1])),int(np.sqrt(single_image_data[:1].shape[1]))\n",
    "            shifted_pic_AxA = shift(digit_image,shift_list[s],cval=0)\n",
    "            shifted_pic_data = np.array(shifted_pic_AxA.reshape(784,))\n",
    "\n",
    "            shifted_pics_data.append(shifted_pic_data)\n",
    "            shifted_pics_labels.append(input_label_list[i]) \n",
    "\n",
    "    X_train_augmented_output = input_data_list.append(pd.DataFrame(shifted_pics_data, columns=input_data_list.columns), ignore_index=True)\n",
    "    y_train_augmented_output = input_label_list.append(pd.Series(shifted_pics_labels), ignore_index=True)\n",
    "    return X_train_augmented_output, y_train_augmented_output\n",
    "\n",
    "X_train_augmented, y_train_augmented = augment_data(X_train_base,y_train_base,desired_shifts)\n",
    "\n",
    "Classifier and CV Accuracy Calculation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "best_estimator = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
    "accuracy_scores = cross_val_score(best_estimator,X_train_augmented,y_train_augmented,cv=3, scoring=\"accuracy\")\n",
    "print(\"Mean Accuracy: \",round(np.mean(accuracy_scores),2))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MaxB2\\AppData\\Local\\Temp\\ipykernel_24972\\2327639519.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train_augmented_output = input_data_list.append(pd.DataFrame(shifted_pics_data, columns=input_data_list.columns), ignore_index=True)\n",
      "C:\\Users\\MaxB2\\AppData\\Local\\Temp\\ipykernel_24972\\2327639519.py:28: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_train_augmented_output = input_label_list.append(pd.Series(shifted_pics_labels), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Data Augmentation XYZXYZXYZXYZ\"\"\"\n",
    "X_train_base = X_train.copy()\n",
    "y_train_base = y_train.copy()\n",
    "\n",
    "from scipy.ndimage import shift\n",
    "import pandas as pd\n",
    "\n",
    "sa = 1\n",
    "desired_shifts = np.array([[0,sa],[0,-sa],[sa,0],[-sa,0]])\n",
    "\n",
    "def augment_data(input_data_list,input_label_list,shift_list): # f(x,y,z)\n",
    "    shifted_pics_data = []\n",
    "    shifted_pics_labels = []\n",
    "    for s in range(len(shift_list)):\n",
    "        for i in range(len(input_data_list)):\n",
    "         \n",
    "            single_image_data = np.array(input_data_list.iloc[i]) \n",
    "\n",
    "            digit_image = np.array(single_image_data.reshape(28,28))\n",
    "            #int(np.sqrt(single_image_data[:1].shape[1])),int(np.sqrt(single_image_data[:1].shape[1]))\n",
    "            shifted_pic_AxA = shift(digit_image,shift_list[s],cval=0)\n",
    "            shifted_pic_data = np.array(shifted_pic_AxA.reshape(784,))\n",
    "\n",
    "            shifted_pics_data.append(shifted_pic_data)\n",
    "            shifted_pics_labels.append(input_label_list[i]) \n",
    "\n",
    "    X_train_augmented_output = input_data_list.append(pd.DataFrame(shifted_pics_data, columns=input_data_list.columns), ignore_index=True)\n",
    "    y_train_augmented_output = input_label_list.append(pd.Series(shifted_pics_labels), ignore_index=True)\n",
    "    return X_train_augmented_output, y_train_augmented_output\n",
    "\n",
    "X_train_augmented, y_train_augmented = augment_data(X_train_base,y_train_base,desired_shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Index:  18607  Original Label:  4\n",
      "New Index:  138607  New Label:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFHUlEQVR4nO3dzSt8URzH8eOhPK08ZGYlTYgNJbGxshcl5S+wkY0SS1srrGSjlCIWmpQ/wIZiY0MxGw8hWYhIovtb/zrfW4Y7M/dj3q/lt5OOenfqzp17pyQIgsABYkoLvQHgJwgXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXkggXksoLvYF8ymQy5ryvr8+bnZ+fm2vr6+sj3RN+hhMXkggXkggXkggXkggXkorqU4V0Om3O397evNnd3Z25lk8V4oETF5IIF5IIF5IIF5JKgiAICr2JXDg9PfVmXV1d5tpkMunNrq+vI99TIczPz3uzy8tLc+3k5KQ36+joiHxPUeDEhSTChSTChSTChSTChST5W76vr6/mfHZ21puVl9v/7sTERKR7KoTHx0dzvri46M2qq6vNtQsLC1FuKac4cSGJcCGJcCGJcCFJ/uLs4ODAnO/u7nqznp4ec611IadmZmbGnN/f33uzvb09c21FRUWke8olTlxIIlxIIlxIIlxIIlxIkvoi+dXVlTfr7+831358fHiz/f19c21bW9vvNpZnDw8P3izsS/LWE8wnJyfm2ubm5l/tK584cSGJcCGJcCGJcCFJ6pbv0tKSNwt7Gnd0dNSbqV2EhVlfX/dm1q1d55wbGBjwZkoXYWE4cSGJcCGJcCGJcCGJcCEplp8qWLd2nXNuZWXFmyUSCXPt3NxclFuKle3t7W+vtX4K6y/gxIUkwoUkwoUkwoWkWF6cnZ2dmXPrdUthLx5OpVKR7ilOwl63ZBkaGsrhTgqHExeSCBeSCBeSCBeSCBeSYvmUr/UUq3POtbS0eLOXlxdzbVNTkzez3ifmnHOdnZ1Z7K7wWltbvVkmkzHXWrd8Dw8PI99TvnHiQhLhQhLhQhLhQlIsb/k2Njaa883NTW82MjJirrW+0xv2mqL29nZvZj0l7Jxz3d3d5vy7BgcHzfnx8bE3a2hoMNeGPdFrsS5S/wJOXEgiXEgiXEgiXEgiXEiK5S3fbNze3przra0tb7azs2OuDXvhcy5UVlaa88/PT28W9tvD7+/v3qympsZce3R05M3CvnyvhBMXkggXkggXkggXkuQvzrLx9fVlzp+fn72Z9as9zjmXTqe9WTKZNNfe3Nx4M+tiyTnn6urqvNnq6qq59unpyZuNjY2Zazc2Nsy5Ok5cSCJcSCJcSCJcSCJcSIrlF8lzpayszJzX1tZ++2+Mj49HtZ3/WE8rWz8LFaa3tzfK7cQeJy4kES4kES4kES4kFdXFWZxNT097s7BXUVnf6Q17eviv4sSFJMKFJMKFJMKFJMKFJD5ViAnrqeQww8PD3sx66fVfxokLSYQLSYQLSYQLSVyc5Zn1+iTnnMvmYeupqamotiOLExeSCBeSCBeSCBeSCBeS+FQhz5aXl8259T6wMNZ7xooNJy4kES4kES4kES4kFdWLneOgqqrKnFu3gktL7XPl4uLCm6VSqd9tTAwnLiQRLiQRLiQRLiQRLiRxyzcmEomEN1tbWzPXFtsnCBZOXEgiXEgiXEgiXEjili8kceJCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFCEuFC0j9OCvAhH8GdsgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFD0lEQVR4nO3dzytscRjH8bkov1Z+ZGYlTYgNJbGxshcl5S+wkY0SS1srrGSjlCIWmpQ/wIZiY0MxGz9CshCRRHN3d/M8p+5cZ+bM59z3a/n0VV/17ltnzpwzv3K5XC4BiCmLegPAvyBcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSCJcSKqIegOFks1mzay/v99de3FxYWYNDQ2h7wnh4cSFJMKFJMKFJMKFJMKFpNh+qpDJZMzs/f3dXXt/f29mfKpQ2jhxIYlwIYlwIYlwIelXLpfLRb2Jnzg7O3Pn3d3dZpZKpdy1Nzc3oe4pCgsLC+786urKzKampty1nZ2doe6pkDhxIYlwIYlwIYlwIYlwIUnqlu/b25uZzc3NuWsrKuy/Njk5GfqeovD09GRmS0tL7tqamhozW1xcDHtLRceJC0mEC0mEC0mEC0lSF2eHh4dmtre3567t7e01s6ALOTWzs7Nm9vDw4K7d3983s8rKytD3VGycuJBEuJBEuJBEuJBEuJBUkl8kv76+ducDAwNm9vn56a49ODgws/b29p9trMgeHx/dufcl+aAnmE9PT82spaXlR/sqBZy4kES4kES4kES4kFSSt3yXl5fdufc07tjYmLtW7ULMs7Gx4c6927uDg4Pu2jhciHk4cSGJcCGJcCGJcCGJcCEp8k8VvNu7q6ur7tpkMmlm8/PzYW+pZOzs7Pz12qCfwoorTlxIIlxIIlxIIlxIivzi7Pz83My8Vy0lEv6Lh9PpdOh7KhXeq5aCDA8PF3AnpYcTF5IIF5IIF5IIF5IIF5Iif8rXe5K1tbXVXfv6+mpmzc3N7lrvnWJdXV157i5abW1t7jybzZpZ0C3fo6OjUPdUKjhxIYlwIYlwIYlwISnyW75NTU1mtrW15a4dHR01s6DXNXmvKero6HDXek8K9/T0uGvzMTQ0ZGYnJyfu2sbGRjMLelmzJ+giNa44cSGJcCGJcCGJcCGJcCEp8lu++bi7uzOz7e1td+3u7q6ZeS97LqSqqioz+/r6ctd6vz388fHhrq2trTWz4+Njd6335fs44MSFJMKFJMKFJMKFJKmLs3x8f3+b2cvLi7vW++WeTCbjrk2lUmZ2e3vrrvUumOrr6921a2trZvb8/OyuHR8fN7PNzU13bVxx4kIS4UIS4UIS4UIS4UJS5F8kL5Ty8nIzq6ur++u/n5iYCHM7f3hPKicSwT8N5enr6wtrO7I4cSGJcCGJcCGJcCEpthdnpWpmZsade6+i8r7Pm0j4Tw//bzhxIYlwIYlwIYlwIYlwIYlPFYos6Klkz8jIiDsPevH1/4QTF5IIF5IIF5IIF5K4OCsg7xVK+TxUPT09HeZ2YoUTF5IIF5IIF5IIF5IIF5L4VKGAVlZWzCzofWCeoPeMgRMXoggXkggXkggXkmL7YudSUF1dbWZBv6RTVmbPkMvLS3dtOp3+2cZigBMXkggXkggXkggXkggXkrjlW2TJZNKdr6+vmxmfHgTjxIUkwoUkwoUkwoUkbvlCEicuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJBEuJP0GO1zwIX6oY+wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Augmented Data Visual Check\"\"\"\n",
    "#original_index = rd.randint(0,X_train_base.shape[0])\n",
    "original_index = rd.randint(0,X_train_base.shape[0])\n",
    "new_index = int(original_index)+rd.randint(1,4)*X_train_base.shape[0]\n",
    "\n",
    "\n",
    "original_image_array = np.array(X_train_augmented.iloc[original_index])\n",
    "new_image_array = np.array(X_train_augmented.iloc[new_index])\n",
    "\n",
    "print(\"Original Index: \", original_index,\" Original Label: \",y_train_augmented[original_index])\n",
    "plot_digit(original_image_array)\n",
    "print(\"New Index: \", new_index,\" New Label: \",y_train_augmented[new_index])\n",
    "plot_digit(new_image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=4, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=4, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9763\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy:  0.97815\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Classifier and CV Accuracy Calculation\"\"\"\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "best_estimator = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
    "accuracy_scores = cross_val_score(best_estimator,X_train_augmented,y_train_augmented,cv=3, scoring=\"accuracy\")\n",
    "print(\"Mean Accuracy: \",np.mean(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"OLD Image Shifter Function\n",
    "X_train_augmented = X_train.copy()\n",
    "y_train_extended = y_train.copy()\n",
    "\n",
    "print(type(X_train_augmented))\n",
    "print(type(y_train_extended))\n",
    "\n",
    "from scipy.ndimage import shift\n",
    "import pandas as pd\n",
    "\n",
    "rightshift = np.array([0,1])\n",
    "leftshift = np.array([0,-1])\n",
    "downshift = np.array([1,0])\n",
    "upshift = np.array([-1,0])\n",
    "shifts = np.array([rightshift,leftshift,downshift,upshift])\n",
    "\n",
    "shifted_digits = []\n",
    "additional_labels = []\n",
    "\n",
    "\n",
    "def create_4_shifted_digits(orig_pic,shiftdirection): # original_pic data and shift_direction is passed\n",
    "    pic_28x28 = np.array(orig_pic.reshape(28,28))\n",
    "    shifted_pic_28x28 = shift(pic_28x28,shiftdirection,cval=0)\n",
    "    shifted_pic_data = np.array(shifted_pic_28x28.reshape(784,))\n",
    "    return shifted_pic_data\n",
    "\n",
    "def augment_data\n",
    "for i in range(len(X_train_augmented)): # input_list to be augmented\n",
    "    for s in range(len(shifts)): # shift_list with [v,h] vectors to be applied\n",
    "        image_array = np.array(X_train_augmented.iloc[i]) \n",
    "        shifted_digits.append(create_4_shifted_digits(image_array,shifts[s])) # shifted_pic where shifted pic data is stored\n",
    "        additional_labels.append(y_train_extended[i]) # label_list where corrosponding labels are stored\n",
    "\n",
    "shifted_digits = pd.DataFrame(shifted_digits, columns=X_train_augmented.columns)\n",
    "additional_labels = pd.Series(additional_labels)\n",
    "\n",
    "X_train_augmented = X_train_augmented.append(shifted_digits, ignore_index=True)\n",
    "y_train_extended = y_train_extended.append(additional_labels, ignore_index=True)\n",
    "\n",
    "\"Classifier and CV Accuracy Calculation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "best_estimator = KNeighborsClassifier(n_neighbors=4, weights='distance')\n",
    "accuracy_scores = cross_val_score(best_estimator,X_train_augmented,y_train_extended,cv=3, scoring=\"accuracy\")\n",
    "print(\"Mean Accuracy: \",round(np.mean(accuracy_scores),2))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
